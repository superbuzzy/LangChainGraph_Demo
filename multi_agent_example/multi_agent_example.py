import os
from typing import Dict, Any, List
from dotenv import load_dotenv

from pydantic import BaseModel, Field
from langchain.prompts import ChatPromptTemplate
from langchain.output_parsers import PydanticOutputParser
from langchain.chat_models import init_chat_model

from langgraph.graph import Graph, END


load_dotenv() 

# å®šä¹‰æ•°æ®ç»“æ„
class ResearchTopic(BaseModel):
    """ç ”ç©¶ä¸»é¢˜"""
    topic: str = Field(description="ç ”ç©¶ä¸»é¢˜")
    keywords: List[str] = Field(description="å…³é”®è¯åˆ—è¡¨")
    research_questions: List[str] = Field(description="ç ”ç©¶é—®é¢˜åˆ—è¡¨")

class ResearchData(BaseModel):
    """ç ”ç©¶æ•°æ®"""
    sources: List[str] = Field(description="ä¿¡æ¯æ¥æº")
    key_findings: List[str] = Field(description="å…³é”®å‘ç°")
    data_quality: str = Field(description="æ•°æ®è´¨é‡è¯„ä¼°")

class AnalysisResult(BaseModel):
    """åˆ†æç»“æœ"""
    summary: str = Field(description="åˆ†ææ‘˜è¦")
    insights: List[str] = Field(description="å…³é”®æ´å¯Ÿ")
    recommendations: List[str] = Field(description="å»ºè®®")

class FinalReport(BaseModel):
    """æœ€ç»ˆæŠ¥å‘Š"""
    title: str = Field(description="æŠ¥å‘Šæ ‡é¢˜")
    executive_summary: str = Field(description="æ‰§è¡Œæ‘˜è¦")
    main_findings: List[str] = Field(description="ä¸»è¦å‘ç°")
    recommendations: List[str] = Field(description="å»ºè®®")
    conclusion: str = Field(description="ç»“è®º")

# å®šä¹‰çŠ¶æ€
class AgentState(BaseModel):
    """å¤šä»£ç†çŠ¶æ€"""
    original_query: str = ""
    research_topic: ResearchTopic = None
    research_data: ResearchData = None
    analysis_result: AnalysisResult = None
    final_report: FinalReport = None
    messages: List[str] = []

class MultiAgentResearchTeam:
    """å¤šä»£ç†ç ”ç©¶å›¢é˜Ÿ"""
    
    def __init__(self, api_key: str = None):
        """åˆå§‹åŒ–"""
        self.llm = init_chat_model(
        "deepseek:deepseek-chat",
        api_key=api_key or os.getenv("DEEPSEEK_API_KEY"),
        temperature=0
    )
        self.graph = self._build_graph()
    
    def _build_graph(self) -> Graph:
        """æ„å»ºå·¥ä½œæµå›¾"""
        # åˆ›å»ºå›¾
        workflow = Graph()
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("research_planner", self._research_planner_agent)
        workflow.add_node("data_collector", self._data_collector_agent)
        workflow.add_node("data_analyst", self._data_analyst_agent)
        workflow.add_node("report_writer", self._report_writer_agent)
        
        # å®šä¹‰è¾¹ï¼ˆå·¥ä½œæµï¼‰
        workflow.add_edge("research_planner", "data_collector")
        workflow.add_edge("data_collector", "data_analyst")
        workflow.add_edge("data_analyst", "report_writer")
        workflow.add_edge("report_writer", END)
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("research_planner")
        
        return workflow
    
    def _research_planner_agent(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """ç ”ç©¶è§„åˆ’ä»£ç† - è´Ÿè´£åˆ†ææŸ¥è¯¢å¹¶åˆ¶å®šç ”ç©¶è®¡åˆ’"""
        print("ğŸ” ç ”ç©¶è§„åˆ’ä»£ç†æ­£åœ¨å·¥ä½œ...")
        
        prompt = ChatPromptTemplate.from_template("""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶è§„åˆ’å¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·çš„æŸ¥è¯¢ï¼Œåˆ¶å®šè¯¦ç»†çš„ç ”ç©¶è®¡åˆ’ã€‚
        
        ç”¨æˆ·æŸ¥è¯¢ï¼š{query}
        
        è¯·åˆ†æè¿™ä¸ªæŸ¥è¯¢å¹¶æä¾›ï¼š
        1. æ˜ç¡®çš„ç ”ç©¶ä¸»é¢˜
        2. 3-5ä¸ªç›¸å…³å…³é”®è¯
        3. 3-5ä¸ªå…·ä½“çš„ç ”ç©¶é—®é¢˜
        
        è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«topicã€keywordsã€research_questionså­—æ®µã€‚
        """)
        
        parser = PydanticOutputParser(pydantic_object=ResearchTopic)
        
        response = self.llm.invoke(
            prompt.format_messages(query=state["original_query"])
        )
        
        try:
            research_topic = parser.parse(response.content)
        except:
            # å¦‚æœè§£æå¤±è´¥ï¼Œåˆ›å»ºé»˜è®¤ç»“æ„
            research_topic = ResearchTopic(
                topic=state["original_query"],
                keywords=["åˆ†æ", "ç ”ç©¶", "è°ƒæŸ¥"],
                research_questions=[f"å…³äº{state['original_query']}çš„å…³é”®é—®é¢˜æœ‰å“ªäº›ï¼Ÿ"]
            )
        
        state["research_topic"] = research_topic
        state["messages"].append(f"ç ”ç©¶è§„åˆ’å®Œæˆï¼š{research_topic.topic}")
        
        return state
    
    def _data_collector_agent(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """æ•°æ®æ”¶é›†ä»£ç† - è´Ÿè´£æ”¶é›†ç›¸å…³ä¿¡æ¯"""
        print("ğŸ“Š æ•°æ®æ”¶é›†ä»£ç†æ­£åœ¨å·¥ä½œ...")
        
        research_topic = state["research_topic"]
        
        prompt = ChatPromptTemplate.from_template("""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®æ”¶é›†å‘˜ã€‚è¯·æ ¹æ®ç ”ç©¶ä¸»é¢˜æ”¶é›†ç›¸å…³ä¿¡æ¯ã€‚
        
        ç ”ç©¶ä¸»é¢˜ï¼š{topic}
        å…³é”®è¯ï¼š{keywords}
        ç ”ç©¶é—®é¢˜ï¼š{questions}
        
        è¯·æ¨¡æ‹Ÿæ”¶é›†æ•°æ®å¹¶æä¾›ï¼š
        1. ä¿¡æ¯æ¥æºåˆ—è¡¨ï¼ˆ3-5ä¸ªï¼‰
        2. å…³é”®å‘ç°ï¼ˆ3-5ä¸ªï¼‰
        3. æ•°æ®è´¨é‡è¯„ä¼°
        
        è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«sourcesã€key_findingsã€data_qualityå­—æ®µã€‚
        """)
        
        parser = PydanticOutputParser(pydantic_object=ResearchData)
        
        response = self.llm.invoke(
            prompt.format_messages(
                topic=research_topic.topic,
                keywords=", ".join(research_topic.keywords),
                questions=", ".join(research_topic.research_questions)
            )
        )
        
        try:
            research_data = parser.parse(response.content)
        except:
            # å¦‚æœè§£æå¤±è´¥ï¼Œåˆ›å»ºé»˜è®¤ç»“æ„
            research_data = ResearchData(
                sources=["å­¦æœ¯è®ºæ–‡", "è¡Œä¸šæŠ¥å‘Š", "ä¸“å®¶è®¿è°ˆ"],
                key_findings=[f"å…³äº{research_topic.topic}çš„é‡è¦å‘ç°"],
                data_quality="ä¸­ç­‰è´¨é‡"
            )
        
        state["research_data"] = research_data
        state["messages"].append(f"æ•°æ®æ”¶é›†å®Œæˆï¼šæ‰¾åˆ°{len(research_data.sources)}ä¸ªä¿¡æ¯æº")
        
        return state
    
    def _data_analyst_agent(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """æ•°æ®åˆ†æä»£ç† - è´Ÿè´£åˆ†ææ”¶é›†çš„æ•°æ®"""
        print("ğŸ”¬ æ•°æ®åˆ†æä»£ç†æ­£åœ¨å·¥ä½œ...")
        
        research_data = state["research_data"]
        research_topic = state["research_topic"]
        
        prompt = ChatPromptTemplate.from_template("""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆã€‚è¯·åˆ†ææ”¶é›†åˆ°çš„ç ”ç©¶æ•°æ®ã€‚
        
        ç ”ç©¶ä¸»é¢˜ï¼š{topic}
        æ•°æ®æ¥æºï¼š{sources}
        å…³é”®å‘ç°ï¼š{findings}
        
        è¯·è¿›è¡Œæ·±å…¥åˆ†æå¹¶æä¾›ï¼š
        1. åˆ†ææ‘˜è¦
        2. å…³é”®æ´å¯Ÿï¼ˆ3-5ä¸ªï¼‰
        3. å»ºè®®ï¼ˆ3-5ä¸ªï¼‰
        
        è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«summaryã€insightsã€recommendationså­—æ®µã€‚
        """)
        
        parser = PydanticOutputParser(pydantic_object=AnalysisResult)
        
        response = self.llm.invoke(
            prompt.format_messages(
                topic=research_topic.topic,
                sources=", ".join(research_data.sources),
                findings=", ".join(research_data.key_findings)
            )
        )
        
        try:
            analysis_result = parser.parse(response.content)
        except:
            # å¦‚æœè§£æå¤±è´¥ï¼Œåˆ›å»ºé»˜è®¤ç»“æ„
            analysis_result = AnalysisResult(
                summary=f"å¯¹{research_topic.topic}çš„åˆ†æç»“æœ",
                insights=[f"å…³äº{research_topic.topic}çš„é‡è¦æ´å¯Ÿ"],
                recommendations=["éœ€è¦è¿›ä¸€æ­¥ç ”ç©¶"]
            )
        
        state["analysis_result"] = analysis_result
        state["messages"].append("æ•°æ®åˆ†æå®Œæˆï¼šç”Ÿæˆäº†å…³é”®æ´å¯Ÿå’Œå»ºè®®")
        
        return state
    
    def _report_writer_agent(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """æŠ¥å‘Šæ’°å†™ä»£ç† - è´Ÿè´£æ’°å†™æœ€ç»ˆæŠ¥å‘Š"""
        print("ğŸ“ æŠ¥å‘Šæ’°å†™ä»£ç†æ­£åœ¨å·¥ä½œ...")
        
        research_topic = state["research_topic"]
        analysis_result = state["analysis_result"]
        
        prompt = ChatPromptTemplate.from_template("""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡æŠ¥å‘Šæ’°å†™å‘˜ã€‚è¯·æ ¹æ®ç ”ç©¶å’Œåˆ†æç»“æœæ’°å†™æœ€ç»ˆæŠ¥å‘Šã€‚
        
        ç ”ç©¶ä¸»é¢˜ï¼š{topic}
        åˆ†ææ‘˜è¦ï¼š{summary}
        å…³é”®æ´å¯Ÿï¼š{insights}
        å»ºè®®ï¼š{recommendations}
        
        è¯·æ’°å†™ä¸€ä»½å®Œæ•´çš„æŠ¥å‘Šï¼ŒåŒ…å«ï¼š
        1. æŠ¥å‘Šæ ‡é¢˜
        2. æ‰§è¡Œæ‘˜è¦
        3. ä¸»è¦å‘ç°ï¼ˆ3-5ä¸ªï¼‰
        4. å»ºè®®ï¼ˆ3-5ä¸ªï¼‰
        5. ç»“è®º
        
        è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«titleã€executive_summaryã€main_findingsã€recommendationsã€conclusionå­—æ®µã€‚
        """)
        
        parser = PydanticOutputParser(pydantic_object=FinalReport)
        
        response = self.llm.invoke(
            prompt.format_messages(
                topic=research_topic.topic,
                summary=analysis_result.summary,
                insights=", ".join(analysis_result.insights),
                recommendations=", ".join(analysis_result.recommendations)
            )
        )
        
        try:
            final_report = parser.parse(response.content)
        except:
            # å¦‚æœè§£æå¤±è´¥ï¼Œåˆ›å»ºé»˜è®¤ç»“æ„
            final_report = FinalReport(
                title=f"{research_topic.topic}ç ”ç©¶æŠ¥å‘Š",
                executive_summary=f"å…³äº{research_topic.topic}çš„ç ”ç©¶æŠ¥å‘Šæ‘˜è¦",
                main_findings=[f"{research_topic.topic}çš„ä¸»è¦å‘ç°"],
                recommendations=analysis_result.recommendations,
                conclusion=f"å¯¹{research_topic.topic}çš„ç»“è®º"
            )
        
        state["final_report"] = final_report
        state["messages"].append("æœ€ç»ˆæŠ¥å‘Šæ’°å†™å®Œæˆ")
        
        return state
    
    def run_research(self, query: str) -> Dict[str, Any]:
        """è¿è¡Œç ”ç©¶æµç¨‹"""
        print(f"ğŸš€ å¼€å§‹ç ”ç©¶ï¼š{query}\n")
        
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = {
            "original_query": query,
            "research_topic": None,
            "research_data": None,
            "analysis_result": None,
            "final_report": None,
            "messages": []
        }
        
        # ç¼–è¯‘å¹¶è¿è¡Œå›¾
        app = self.graph.compile()
        result = app.invoke(initial_state)
        
        return result
    
    def print_results(self, result: Dict[str, Any]):
        """æ‰“å°ç»“æœ"""
        print("\n" + "="*50)
        print("ğŸ“‹ ç ”ç©¶ç»“æœ")
        print("="*50)
        
        if result.get("final_report"):
            report = result["final_report"]
            print(f"\nğŸ“– æ ‡é¢˜ï¼š{report.title}")
            print(f"\nğŸ“„ æ‰§è¡Œæ‘˜è¦ï¼š\n{report.executive_summary}")
            print(f"\nğŸ” ä¸»è¦å‘ç°ï¼š")
            for i, finding in enumerate(report.main_findings, 1):
                print(f"{i}. {finding}")
            print(f"\nğŸ’¡ å»ºè®®ï¼š")
            for i, rec in enumerate(report.recommendations, 1):
                print(f"{i}. {rec}")
            print(f"\nğŸ“ ç»“è®ºï¼š\n{report.conclusion}")
        
        print(f"\nğŸ”„ å¤„ç†æµç¨‹ï¼š")
        for i, msg in enumerate(result["messages"], 1):
            print(f"{i}. {msg}")

# ä½¿ç”¨ç¤ºä¾‹
def main():
    """ä¸»å‡½æ•°"""
    api_key = os.environ["DEEPSEEK_API_KEY"]

    # åˆ›å»ºç ”ç©¶å›¢é˜Ÿ
    team = MultiAgentResearchTeam(api_key=api_key)
    
    # å®šä¹‰ç ”ç©¶æŸ¥è¯¢
    query = "äººå·¥æ™ºèƒ½åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨å‰æ™¯"
    
    # è¿è¡Œç ”ç©¶
    result = team.run_research(query)
    
    # æ‰“å°ç»“æœ
    team.print_results(result)

if __name__ == "__main__":
    main()
